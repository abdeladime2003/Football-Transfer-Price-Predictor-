{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using the \"name.csv\" file to retrieve player statistics. If the player exists on the website 'https://www.fifaratings.com', we collect their statistics. Otherwise, we assign a value of 0 to all columns to signify that the player was not found on the website. The scraped data will be stored in a CSV file named \"stats.csv\"."
      ],
      "metadata": {
        "id": "LPKgK7PGbYD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import re"
      ],
      "metadata": {
        "trusted": true,
        "id": "KsbC8oHybYD7"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the names from the csv file and store it in name_list\n",
        "def read_names_from_csv(csv_file):\n",
        "  name_list = []\n",
        "  with open(csv_file, 'r') as file:    # the csv file that contains names is names.csv\n",
        "    next(file)\n",
        "    k = 0\n",
        "    for line in file:\n",
        "      name_list.append(line.split(',')[1].replace(' ', '-').replace('\\n', ''))\n",
        "  return name_list"
      ],
      "metadata": {
        "trusted": true,
        "id": "fviZP4WrbYD-"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# scrapping the values from the website\n",
        "\n",
        "def scrape_player_data(name_list):\n",
        "  player_not_found = []\n",
        "  skills_stat = []\n",
        "\n",
        "\n",
        "  for name in name_list:\n",
        "    url = f\"https://www.fifaratings.com/{name}\"\n",
        "    html_text = requests.get(url, headers={'user-agent':\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0\"}).text\n",
        "    soup = bs(html_text, \"lxml\")\n",
        "\n",
        "    players = soup.find_all(\"span\", class_ = \"mr-n1\")\n",
        "    temp = []\n",
        "    for item in players:\n",
        "        temp.append(item.text)\n",
        "\n",
        "    if temp == []:\n",
        "        player_not_found.append(name)\n",
        "    else:\n",
        "        skills_stat.append(temp)\n",
        "  return skills_stat, player_not_found"
      ],
      "metadata": {
        "trusted": true,
        "id": "LC4nBE8ubYD-"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the uneccessary values from skills_stat\n",
        "\n",
        "def clean_player_data(skills_stat):\n",
        "  index_to_remove = [2 * i + 1 for i in range(8)]\n",
        "\n",
        "\n",
        "  for item in skills_stat:\n",
        "    for index in sorted(index_to_remove, reverse=True):\n",
        "        del item[index]\n",
        "    del item[-1]\n",
        "  return skills_stat"
      ],
      "metadata": {
        "trusted": true,
        "id": "w5cI-l8YbYD_"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# combining skill_name and skills_stat\n",
        "\n",
        "def combine_data(name_list, skills_stat, player_not_found):\n",
        "    data = []\n",
        "    columns = [\"ATT\", \"SKI\", \"MOV\", \"POW\", \"MEN\", \"DEF\", \"GK\"]  # the skills that we want to scrap\n",
        "\n",
        "    for i, name in enumerate(name_list):\n",
        "        player = {}\n",
        "        if name in player_not_found:\n",
        "            player[\"name\"] = name.replace('-', ' ')\n",
        "            for column in columns:\n",
        "                player[column] = np.nan\n",
        "        else:\n",
        "          if i < len(skills_stat):\n",
        "            player[\"name\"] = name.replace('-', ' ')\n",
        "            for index, column in enumerate(columns):\n",
        "                player[column] = skills_stat[i][index]\n",
        "        data.append(player)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "trusted": true,
        "id": "B6EUNy8FbYD_"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_csv(data, output_csv_file):\n",
        "    fields = data[0].keys()\n",
        "\n",
        "    with open(output_csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EX91wuS7bYD_"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "# File paths\n",
        "csv_file = 'name.csv'\n",
        "output_csv_file = 'stats.csv'\n",
        "\n",
        "# Read names from CSV\n",
        "name_list = read_names_from_csv(csv_file)\n",
        "\n",
        "# Scrape player data\n",
        "skills_stat, player_not_found = scrape_player_data(name_list)\n",
        "\n",
        "# Clean player data\n",
        "clean_player_data(skills_stat)\n",
        "\n",
        "# Combine data\n",
        "data = combine_data(name_list, skills_stat, player_not_found)\n",
        "\n",
        "# Save to CSV\n",
        "save_to_csv(data, output_csv_file)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Qzdnz59-bYEA"
      },
      "outputs": [],
      "execution_count": 7
    }
  ]
}